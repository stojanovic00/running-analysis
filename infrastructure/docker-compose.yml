services:

  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
      - ../datasets:/localDatasets
      - ../batch:/scripts
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop.env
    ports:
      - 9870:9870
      - 9000:9000
    ulimits: &ulimits_def
      nofile:
        soft: 65536
        hard: 65536


  datanode1:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode1
    depends_on: 
      - namenode
    volumes:
      - hadoop_datanode1:/hadoop/dfs/data
    env_file:
      - ./hadoop.env
    ulimits: *ulimits_def


  datanode2:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode2
    depends_on: 
      - namenode
    volumes:
      - hadoop_datanode2:/hadoop/dfs/data
    env_file:
      - ./hadoop.env
    ulimits: *ulimits_def

  spark-master:
    image: bde2020/spark-master:${SPARK_MASTER_VERSION:-3.0.1-hadoop3.2}
    container_name: spark-master
    ports:
      - 8080:8080
      - 7077:7077
    environment: 
      - PYSPARK_PYTHON=python3
    env_file:
      - ./hadoop.env
    volumes:
      - ../batch:/batch-scripts
      - ../stream/streams:/stream-scripts

  spark-worker1:
    image: bde2020/spark-worker:${SPARK_WORKER_VERSION:-3.0.1-hadoop3.2}
    container_name: spark-worker1
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER=spark://spark-master:7077
    ports:
      - 8081:8081
    env_file:
      - ./hadoop.env
  
  spark-worker2:
    image: bde2020/spark-worker:${SPARK_WORKER_VERSION:-3.0.1-hadoop3.2}
    container_name: spark-worker2
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER=spark://spark-master:7077
    ports:
      - 8082:8081
    env_file:
      - ./hadoop.env
  
  citus-coordinator:
    image:  "citusdata/citus:12.1.1"
    container_name: citus-coordinator
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: running-analytics
      PGDATA: /var/lib/postgresql/data/pgdata
      CITUS_MASTER: true
    volumes:
      - citus-coordinator:/var/lib/postgresql/data
    ports:
      - "5000:5432"

  citus-node1:
    image: "citusdata/citus:12.1.1"
    container_name: citus-node1
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: running-analytics
      PGDATA: /var/lib/postgresql/data/pgdata
      CITUS_WORKER: 1
      CITUS_MASTER_HOST: citus-coordinator
    depends_on:
      - citus-coordinator
    volumes:
      - citus-node1:/var/lib/postgresql/data

  citus-node2:
    image:  "citusdata/citus:12.1.1"
    container_name: citus-node2
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: running-analytics
      PGDATA: /var/lib/postgresql/data/pgdata
      CITUS_WORKER: 2
      CITUS_MASTER_HOST: citus-coordinator
    depends_on:
      - citus-coordinator
    volumes:
      - citus-node2:/var/lib/postgresql/data

  metabase-db:
    image: postgres:13.1-alpine
    container_name: metabase-db
    restart: always
    volumes:
      - metabase-db:/var/lib/postgresql/data
    environment:
      - POSTGRES_DB=metabase-db
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres

  metabase:
    image: metabase/metabase:latest
    container_name: metabase
    restart: always
    environment:
      MB_DB_TYPE: "postgres"
      MB_DB_DBNAME: "metabase-db"
      MB_DB_PORT: "5432"
      MB_DB_USER: "postgres"
      MB_DB_PASS: "postgres"
      MB_DB_HOST: "metabase-db"
    ports:
      - 3000:3000
    depends_on:
      - metabase-db

  hue:
    image: gethue/hue:20201111-135001
    hostname: hue
    container_name: hue
    dns: 8.8.8.8
    ports:
      - "8888:8888"
    volumes:
      - ./conf.dist:/usr/share/hue/desktop/conf
    depends_on: 
      - namenode


  zoo:
    image: zookeeper:3.4.9
    container_name: zoo
    ports:
      - "2181:2181"
    environment:
        ZOO_MY_ID: 1
        ZOO_PORT: 2181
        ZOO_SERVERS: server.1=zoo:2888:3888
    volumes:
      - zoo:/data
      - zoolog:/datalog
    ulimits: *ulimits_def


  kafka1:
    image: confluentinc/cp-kafka:latest
    container_name: kafka1
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka1:19092,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092
      #KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka1:19092,LISTENER_DOCKER_EXTERNAL://kafka1:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zoo:2181"
      KAFKA_BROKER_ID: 1
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
    volumes:
      - kafka1:/var/lib/kafka/data
    depends_on:
      - zoo
    ulimits: *ulimits_def
    restart: always

  kafka2:
    image: confluentinc/cp-kafka:latest
    container_name: kafka2
    ports:
      - "9093:9093"
    environment:
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka2:19093,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9093
      #KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka2:19093,LISTENER_DOCKER_EXTERNAL://kafka2:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zoo:2181"
      KAFKA_BROKER_ID: 2
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
    volumes:
      - kafka2:/var/lib/kafka/data
    depends_on:
      - zoo
    ulimits: *ulimits_def
    restart: always


  kafka3:
    image: confluentinc/cp-kafka:latest
    container_name: kafka3
    ports:
      - "9094:9094"
    environment:
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka3:19094,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9094
      #KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka3:19094,LISTENER_DOCKER_EXTERNAL://kafka3:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zoo:2181"
      KAFKA_BROKER_ID: 3
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
    volumes:
      - kafka3:/var/lib/kafka/data
    depends_on:
      - zoo
    ulimits: *ulimits_def
    restart: always

  streams-db:
    image: mongo:latest
    container_name: streams-db
    ports:
      - "27017:27017"
    volumes:
      - streams-db:/data/db
    environment:
      MONGO_INITDB_ROOT_USERNAME: mongo
      MONGO_INITDB_ROOT_PASSWORD: mongo


volumes:
  hadoop_namenode:
  hadoop_datanode1:
  hadoop_datanode2:
  zoo:
  zoolog:
  kafka1:
  kafka2:
  kafka3:
  citus-coordinator:
  citus-node1:
  citus-node2:
  metabase-db:
  streams-db:
