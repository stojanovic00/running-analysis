{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-02T23:35:08.230134348Z",
     "start_time": "2024-01-02T23:35:08.183231317Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr, when,monotonically_increasing_id\n",
    "\n",
    "conf = SparkConf() \\\n",
    "    .setAppName(\"batch-preprocessing\") \\\n",
    "    .set(\"spark.jars\", \"./libs/postgresql-42.7.1.jar\") \\\n",
    "    .setMaster(\"local\")\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .config(conf=conf) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# SB Config\n",
    "jdbc_url = \"jdbc:postgresql://localhost:5000/running-analytics\"\n",
    "pg_properties = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"postgres\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [],
   "source": [
    "# Loading dataset and initial dataframe preparation\n",
    "df = spark.read.csv(\"../datasets/batch_sample.csv\", header=True, inferSchema=True)\n",
    "df = df.select([col(c).alias(c.replace(\" \", \"_\")) for c in df.columns])\n",
    "df = df.select([col(c).alias(c.lower()) for c in df.columns])\n",
    "\n",
    "df = df.withColumn(\"athlete_age\", col(\"year_of_event\").cast(\"int\") - col(\"athlete_year_of_birth\").cast(\"int\"))\n",
    "df = df.drop(\"athlete_age_category\")\n",
    "df = df.withColumn(\"athlete_year_of_birth\", col(\"athlete_year_of_birth\").cast(\"int\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T23:35:08.334073234Z",
     "start_time": "2024-01-02T23:35:08.229787510Z"
    }
   },
   "id": "d4bfc4381907fb08"
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "# Separating races to types and processing time  constrained df\n",
    "marathon_type_filter = (col(\"event_distance/length\").contains(\"d\") |\n",
    "                        col(\"event_distance/length\").contains(\"h\"))\n",
    "# Create two separate DataFrames based on the condition\n",
    "time_constrained_df = df.filter(marathon_type_filter)\n",
    "distance_constrained_df = df.filter(~marathon_type_filter)\n",
    "\n",
    "# Time based marathons processing\n",
    "time_constrained_df = time_constrained_df.withColumnRenamed(\"event_distance/length\", \"time_limit\")\n",
    "time_constrained_df = time_constrained_df.withColumnRenamed(\"athlete_performance\", \"distance_crossed\")\n",
    "\n",
    "# Normalize time to hours\n",
    "days_expr = \"(CASE WHEN time_limit LIKE '%d%' THEN CAST(regexp_extract(time_limit, '([0-9]+)', 1) AS INT) ELSE 0 END) * 24\"\n",
    "hours_expr = \"(CASE WHEN time_limit LIKE '%h%' THEN CAST(regexp_extract(time_limit, '([0-9]+)', 1) AS INT) ELSE 0 END)\"\n",
    "\n",
    "time_constrained_df = time_constrained_df.withColumn(\"time_limit_h\", expr(f\"{days_expr} + {hours_expr}\"))\n",
    "time_constrained_df = time_constrained_df.drop(\"time_limit\")\n",
    "\n",
    "# Normalize crossed distance to km\n",
    "distance_expr = \"\"\"\n",
    "                  ROUND(\n",
    "                  CASE \n",
    "                  WHEN distance_crossed LIKE '%km%' THEN CAST(regexp_extract(distance_crossed, '([0-9]+(.[0-9]+)?)', 1) AS FLOAT) \n",
    "                  WHEN distance_crossed LIKE '%mi%' THEN CAST(regexp_extract(distance_crossed, '([0-9]+(.[0-9]+)?)', 1) AS FLOAT) *1.609344 \n",
    "                  ELSE 0 \n",
    "                  END, 4)\n",
    "              \"\"\"\n",
    "\n",
    "time_constrained_df = time_constrained_df.withColumn(\"distance_crossed_km\", expr(f\"{distance_expr}\"))\n",
    "time_constrained_df = time_constrained_df.drop(\"distance_crossed\")\n",
    "\n",
    "\n",
    "time_constrained_df = time_constrained_df.withColumn(\n",
    "    \"athlete_average_speed_kmph\",\n",
    "    when(col(\"athlete_average_speed\").cast(\"double\") > 50, col(\"athlete_average_speed\").cast(\"double\") / 1000).\n",
    "    otherwise(col(\"athlete_average_speed\").cast(\"double\"))\n",
    ")\n",
    "time_constrained_df = time_constrained_df.drop(\"athlete_average_speed\")\n",
    "\n",
    "# Add an artificial key column\n",
    "time_constrained_df = time_constrained_df.withColumn(\"id\", monotonically_increasing_id())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T23:35:08.380061816Z",
     "start_time": "2024-01-02T23:35:08.337480292Z"
    }
   },
   "id": "db9effd1ef82cc7e"
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [],
   "source": [
    "# Writing time_constrained to db\n",
    "time_constrained_df.write.jdbc(jdbc_url, \"public.running_time_constrained\", mode=\"overwrite\", properties=pg_properties)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T23:35:08.497763312Z",
     "start_time": "2024-01-02T23:35:08.379815342Z"
    }
   },
   "id": "552ae3d363758172"
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [],
   "source": [
    "distance_constrained_df = distance_constrained_df.withColumnRenamed(\"event_distance/length\", \"distance\")\n",
    "distance_constrained_df = distance_constrained_df.withColumnRenamed(\"athlete_performance\", \"time_spent\")\n",
    "\n",
    "distance_expr = \"\"\"\n",
    "                  ROUND(\n",
    "                  CASE \n",
    "                  WHEN distance LIKE '%km%' THEN CAST(regexp_extract(distance, '([0-9]+(.[0-9]+)?)', 1) AS FLOAT) \n",
    "                  WHEN distance LIKE '%mi%' THEN CAST(regexp_extract(distance, '([0-9]+(.[0-9]+)?)', 1) AS FLOAT) *1.609344 \n",
    "                  ELSE 0 \n",
    "                  END, 4)\n",
    "              \"\"\"\n",
    "\n",
    "\n",
    "distance_constrained_df = distance_constrained_df.withColumn(\"distance_km\", expr(f\"{distance_expr}\"))\n",
    "distance_constrained_df = distance_constrained_df.drop(\"distance\")\n",
    "\n",
    "# Normalizing time to seconds for easier manipulation later\n",
    "# Extract components\n",
    "days_expr = \"CASE WHEN time_spent LIKE '%d%' THEN CAST(regexp_extract(time_spent, '([0-9]+)d', 1) AS INT) ELSE 0 END\"\n",
    "hours_expr = \"CAST(regexp_extract(time_spent, '([0-9]+):([0-9]{2}):([0-9]{2})', 1) AS INT)\"\n",
    "minutes_expr = \"CAST(regexp_extract(time_spent, '([0-9]+):([0-9]{2}):([0-9]{2})', 2) AS INT)\"\n",
    "seconds_expr = \"CAST(regexp_extract(time_spent, '([0-9]+):([0-9]{2}):([0-9]{2})', 3) AS INT)\"\n",
    "\n",
    "# Convert to seconds and sum up\n",
    "total_seconds_expr = f\"({days_expr} * 24 * 60 * 60) + ({hours_expr} * 60 * 60) + ({minutes_expr} * 60) + {seconds_expr}\"\n",
    "\n",
    "# Add a new column 'total_duration_seconds'\n",
    "distance_constrained_df = distance_constrained_df.withColumn(\"time_spent_s\", expr(total_seconds_expr))\n",
    "\n",
    "\n",
    "# Normalize average speed to km/h\n",
    "distance_constrained_df = distance_constrained_df.withColumn(\n",
    "    \"athlete_average_speed_kmph\",\n",
    "     when(col(\"athlete_average_speed\").cast(\"double\") > 50, col(\"athlete_average_speed\").cast(\"double\") / 1000).\n",
    "     otherwise(col(\"athlete_average_speed\").cast(\"double\"))\n",
    ")\n",
    "distance_constrained_df = distance_constrained_df.drop(\"athlete_average_speed\")\n",
    "\n",
    "# Add an artificial key column\n",
    "distance_constrained_df = distance_constrained_df.withColumn(\"id\", monotonically_increasing_id())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T23:35:08.543513452Z",
     "start_time": "2024-01-02T23:35:08.500629719Z"
    }
   },
   "id": "f6780a2bbfa81511"
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "# Writing distance_constrained to db\n",
    "distance_constrained_df.write.jdbc(jdbc_url, \"public.running_distance_constrained\", mode=\"overwrite\", properties=pg_properties)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T23:37:10.657863356Z",
     "start_time": "2024-01-02T23:37:10.554509911Z"
    }
   },
   "id": "97ac294273556ee2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
